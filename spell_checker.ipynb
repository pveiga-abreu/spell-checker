{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "optimum-september",
   "metadata": {},
   "source": [
    "# Creating the checker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-affiliate",
   "metadata": {},
   "source": [
    "#### Tokenize articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "disturbed-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "numerical-rebel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant\n",
    "ALPHABET = 'abcdefghijklmopqrstuvwxyzáâàãéêèíîìóôòõúûùç'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "royal-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('artigos.txt', 'r', encoding='utf8') as f:\n",
    "    articles = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sensitive-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.tokenize.word_tokenize(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "careful-conditions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515907\n",
      "['imagem', 'Temos', 'a', 'seguinte', 'classe', 'que', 'representa', 'um', 'usuário', 'no', 'nosso', 'sistema', ':', 'java', 'Para', 'salvar', 'um', 'novo', 'usuário', ',', 'várias', 'validações', 'são', 'feitas', ',', 'como', 'por', 'exemplo', ':', 'Ver', 'se', 'o', 'nome', 'só', 'contém', 'letras', ',', '[', '*', '*']\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))\n",
    "print(tokens[:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-musician",
   "metadata": {},
   "source": [
    "#### Separating words from tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "complimentary-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_words(tokens: list) -> list:\n",
    "    '''\n",
    "    Generates tokens\n",
    "    '''\n",
    "    return [ token for token in tokens if token.isalpha() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "liked-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = separate_words(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "veterinary-valentine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403106\n",
      "['imagem', 'Temos', 'a', 'seguinte', 'classe', 'que', 'representa', 'um', 'usuário', 'no', 'nosso', 'sistema', 'java', 'Para', 'salvar', 'um', 'novo', 'usuário', 'várias', 'validações', 'são', 'feitas', 'como', 'por', 'exemplo', 'Ver', 'se', 'o', 'nome', 'só', 'contém', 'letras', 'o', 'CPF', 'só', 'números', 'e', 'ver', 'se', 'o']\n"
     ]
    }
   ],
   "source": [
    "print(len(words))\n",
    "print(words[:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-fleece",
   "metadata": {},
   "source": [
    "#### putting all on lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "educated-buffalo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(words: list) -> list:\n",
    "    '''\n",
    "    Puts all words on the list in lower case\n",
    "    '''\n",
    "    return [ word.lower() for word in words ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "proud-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_words = normalize(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "extraordinary-museum",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403106\n",
      "['imagem', 'temos', 'a', 'seguinte', 'classe', 'que', 'representa', 'um', 'usuário', 'no', 'nosso', 'sistema', 'java', 'para', 'salvar', 'um', 'novo', 'usuário', 'várias', 'validações', 'são', 'feitas', 'como', 'por', 'exemplo', 'ver', 'se', 'o', 'nome', 'só', 'contém', 'letras', 'o', 'cpf', 'só', 'números', 'e', 'ver', 'se', 'o']\n"
     ]
    }
   ],
   "source": [
    "print(len(norm_words))\n",
    "print(norm_words[:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parallel-edgar",
   "metadata": {},
   "source": [
    "#### Total words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "smaller-kuwait",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18465\n"
     ]
    }
   ],
   "source": [
    "print(len(set(norm_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-inclusion",
   "metadata": {},
   "source": [
    "#### Slicing and generate new words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "front-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_letters(slices: list) -> tuple:\n",
    "    '''\n",
    "    Insert all letters of the Portuguese alphabet in the sliced word\n",
    "    '''\n",
    "    generated_words = list()\n",
    "    \n",
    "    for left, right in slices:\n",
    "        for letter in ALPHABET: \n",
    "            generated_words.append(left + letter + right)\n",
    "    \n",
    "    return tuple(generated_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "emotional-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_letters(slices: list) -> tuple:\n",
    "    '''\n",
    "    Deletes a letter from a word\n",
    "    '''\n",
    "    generated_words = list()\n",
    "\n",
    "    for left, right in slices:\n",
    "        generated_words.append(left + right[1:])\n",
    "\n",
    "    return tuple(generated_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-discovery",
   "metadata": {},
   "source": [
    "#### Words generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "primary-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_words(word: str) -> str:\n",
    "    '''\n",
    "    Generates possible correct keywords \n",
    "    '''\n",
    "    slices = [ (word[:i], word[i:]) for i in range(len(word)+1) ]\n",
    "    \n",
    "    generated_words = insert_letters(slices)\n",
    "    generated_words += delete_letters(slices)\n",
    "    \n",
    "    return generated_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-demonstration",
   "metadata": {},
   "source": [
    "#### Creating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "handmade-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = nltk.FreqDist(norm_words)\n",
    "total_words = len(norm_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "modern-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(word: str) -> float:\n",
    "    '''\n",
    "    Calculates the probability of the word being correct\n",
    "    '''\n",
    "    return freq[word]/total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "controversial-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(word: str) -> str:\n",
    "    '''\n",
    "    Checks the probabilities of all words\n",
    "    '''\n",
    "    generated_words = generate_words(word)\n",
    "    correct = max(generated_words, key=probability)\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "apart-edwards",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check('lóigica')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-motion",
   "metadata": {},
   "source": [
    "#### Testing the checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "blocked-longitude",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('podemos', 'pyodemos'),\n",
       " ('esse', 'esje'),\n",
       " ('já', 'jrá'),\n",
       " ('nosso', 'nossov'),\n",
       " ('são', 'sãêo'),\n",
       " ('dos', 'dosa'),\n",
       " ('muito', 'muifo'),\n",
       " ('imagem', 'iômagem'),\n",
       " ('sua', 'ósua'),\n",
       " ('também', 'tambéùm'),\n",
       " ('ele', 'eme'),\n",
       " ('fazer', 'èazer'),\n",
       " ('temos', 'temfs'),\n",
       " ('essa', 'eàssa'),\n",
       " ('quando', 'quaôdo'),\n",
       " ('vamos', 'vamvos'),\n",
       " ('sobre', 'hsobre'),\n",
       " ('java', 'sjava'),\n",
       " ('das', 'daõs'),\n",
       " ('agora', 'agorah'),\n",
       " ('está', 'eòtá'),\n",
       " ('cada', 'céda'),\n",
       " ('mesmo', 'zmesmo'),\n",
       " ('nos', 'noâ'),\n",
       " ('forma', 'fobma'),\n",
       " ('seja', 'sejéa'),\n",
       " ('então', 'enêão'),\n",
       " ('criar', 'èriar'),\n",
       " ('código', 'cóeigo'),\n",
       " ('caso', 'casío'),\n",
       " ('exemplo', 'áexemplo'),\n",
       " ('tem', 'tĩem'),\n",
       " ('usuário', 'usuárôio'),\n",
       " ('dados', 'dfados'),\n",
       " ('python', 'pgthon'),\n",
       " ('nossa', 'nossah'),\n",
       " ('além', 'alémè'),\n",
       " ('assim', 'asõim'),\n",
       " ('ter', 'teb'),\n",
       " ('até', 'atĩ'),\n",
       " ('bem', 'âem'),\n",
       " ('design', 'desigen'),\n",
       " ('trabalho', 'trabalàho'),\n",
       " ('foi', 'foo'),\n",
       " ('apenas', 'apenaũ'),\n",
       " ('empresa', 'empresà'),\n",
       " ('valor', 'valíor'),\n",
       " ('será', 'serr'),\n",
       " ('entre', 'entke'),\n",
       " ('método', 'méqodo'),\n",
       " ('precisamos', 'precisamops'),\n",
       " ('ainda', 'ainàa'),\n",
       " ('vai', 'van'),\n",
       " ('conteúdo', 'ûconteúdo'),\n",
       " ('seus', 'çeus'),\n",
       " ('eu', 'eû'),\n",
       " ('todos', 'todtos'),\n",
       " ('tempo', 'temeo'),\n",
       " ('sempre', 'semre'),\n",
       " ('qual', 'quakl'),\n",
       " ('ela', 'elaá'),\n",
       " ('só', 'síó'),\n",
       " ('utilizar', 'utiqizar'),\n",
       " ('projeto', 'prhojeto'),\n",
       " ('site', 'siàe'),\n",
       " ('sem', 'seém'),\n",
       " ('pelo', 'peln'),\n",
       " ('alura', 'aléra'),\n",
       " ('dia', 'tdia'),\n",
       " ('tudo', 'tuúo'),\n",
       " ('podemos', 'kpodemos'),\n",
       " ('esse', 'eẽsse'),\n",
       " ('já', 'jé'),\n",
       " ('nosso', 'nçosso'),\n",
       " ('são', 'sãô'),\n",
       " ('dos', 'odos'),\n",
       " ('muito', 'tuito'),\n",
       " ('imagem', 'imõgem'),\n",
       " ('sua', 'siua'),\n",
       " ('também', 'tamvbém'),\n",
       " ('ele', 'elpe'),\n",
       " ('fazer', 'façzer'),\n",
       " ('temos', 'teos'),\n",
       " ('essa', 'eũsa'),\n",
       " ('quando', 'quaìdo'),\n",
       " ('vamos', 'vjmos'),\n",
       " ('sobre', 'sxobre'),\n",
       " ('java', 'jkva'),\n",
       " ('das', 'dms'),\n",
       " ('agora', 'agtora'),\n",
       " ('está', 'esútá'),\n",
       " ('cada', 'cava'),\n",
       " ('mesmo', 'medmo'),\n",
       " ('nos', 'ános'),\n",
       " ('forma', 'forûa'),\n",
       " ('seja', 'smeja'),\n",
       " ('então', 'enjtão'),\n",
       " ('criar', 'criôar'),\n",
       " ('código', 'cóàigo'),\n",
       " ('caso', 'èaso'),\n",
       " ('exemplo', 'exbemplo'),\n",
       " ('tem', 'túem'),\n",
       " ('usuário', 'usuárin'),\n",
       " ('dados', 'daáos'),\n",
       " ('python', 'pythoçn'),\n",
       " ('nossa', 'nossk'),\n",
       " ('além', 'âlém'),\n",
       " ('assim', 'aóssim'),\n",
       " ('ter', 'tãer'),\n",
       " ('até', 'vté'),\n",
       " ('bem', 'búm'),\n",
       " ('design', 'íesign'),\n",
       " ('trabalho', 'trabèalho'),\n",
       " ('foi', 'kfoi'),\n",
       " ('apenas', 'aapenas'),\n",
       " ('empresa', 'pmpresa'),\n",
       " ('valor', 'valoqr'),\n",
       " ('será', 'sçerá'),\n",
       " ('entre', 'entró'),\n",
       " ('método', 'nétodo'),\n",
       " ('precisamos', 'prefcisamos'),\n",
       " ('ainda', 'sainda'),\n",
       " ('vai', 'uai'),\n",
       " ('conteúdo', 'cĩonteúdo'),\n",
       " ('seus', 'sâus'),\n",
       " ('eu', 'ìeu'),\n",
       " ('todos', 'todás'),\n",
       " ('tempo', 'utempo'),\n",
       " ('sempre', 'sempce'),\n",
       " ('qual', 'fual'),\n",
       " ('ela', 'elal'),\n",
       " ('só', 'skó'),\n",
       " ('utilizar', 'utilĩzar'),\n",
       " ('projeto', 'proójeto'),\n",
       " ('site', 'isite'),\n",
       " ('sem', 'secm'),\n",
       " ('pelo', 'pẽlo'),\n",
       " ('alura', 'aluéa'),\n",
       " ('dia', 'dil'),\n",
       " ('tudo', 'tudy'),\n",
       " ('ela', 'qelay'),\n",
       " ('só', 'sód'),\n",
       " ('utilizar', 'dtilizacr'),\n",
       " ('projeto', 'bprojõto'),\n",
       " ('site', 'ysiteo'),\n",
       " ('sem', 'sõêm'),\n",
       " ('pelo', 'peàli'),\n",
       " ('alura', 'asuraó'),\n",
       " ('dia', 'deiìa'),\n",
       " ('tudo', 'tuĩdoì'),\n",
       " ('ela', 'eúaa'),\n",
       " ('só', 'ró'),\n",
       " ('utilizar', 'utilizẽaçr'),\n",
       " ('projeto', 'prêjetó'),\n",
       " ('site', 'sqiqte'),\n",
       " ('sem', 'sũexm'),\n",
       " ('pelo', 'pçlxo'),\n",
       " ('alura', 'uluraa'),\n",
       " ('dia', 'dĩaz'),\n",
       " ('tudo', 'kzudo'),\n",
       " ('corretor', 'correptor'),\n",
       " ('tática', 'trtica'),\n",
       " ('empoderamento', 'ewpoderamento'),\n",
       " ('linux', 'lifux'),\n",
       " ('cachorro', 'cachoçro'),\n",
       " ('gato', 'îgato'),\n",
       " ('cavalo', 'cakvalo'),\n",
       " ('relógio', 'relógiuo'),\n",
       " ('canela', 'canelac'),\n",
       " ('tênis', 'tênisy'),\n",
       " ('ansiosa', 'anciosa'),\n",
       " ('ansiosa', 'ancciosa'),\n",
       " ('ansiosa', 'ansioa'),\n",
       " ('empoderamento', 'empoderamento'),\n",
       " ('asterisco', 'asterístico'),\n",
       " ('gratuito', 'gratuíto'),\n",
       " ('entretido', 'entertido'),\n",
       " ('ritmo', 'ritimo'),\n",
       " ('idiota', 'indiota'),\n",
       " ('tomara', 'tomare'),\n",
       " ('seja', 'seje'),\n",
       " ('prevalecer', 'provalecer'),\n",
       " ('esteja', 'esteje'),\n",
       " ('mendigo', 'mindigo'),\n",
       " ('cérebro', 'célebro'),\n",
       " ('perturbar', 'pertubar')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating test data\n",
    "test_words = list()\n",
    "with open('palavras.txt', 'r', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        c, w = line.split()\n",
    "        test_words.append((c, w))\n",
    "\n",
    "test_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "critical-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_words: list) -> None:\n",
    "    num_words = len(test_words)\n",
    "    corrects = 0\n",
    "    \n",
    "    for c, w in test_words:\n",
    "        resp = check(w)\n",
    "        if resp == c: corrects += 1\n",
    "    \n",
    "    rate = round(corrects*100/num_words, 2)\n",
    "    print(f'Rate: {rate}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "unlike-choice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate: 41.4%\n"
     ]
    }
   ],
   "source": [
    "test(test_words) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
